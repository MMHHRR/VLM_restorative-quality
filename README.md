Visual language models as students in assessing the psychological restorative quality of campus space
Abstract: Campus environments significantly impact student stress reduction and mental well-being through restorative quality. However, current assessment methods are limited. Subjective surveys lack spatial scalability, while objective machine learning often fails to capture human perceptual complexity. This study therefore proposes an innovative Vision Language Model (VLM)-based method to bridge this gap. Specifically, we design prompts to guide VLMs in evaluating 933 campus street view images (SVIs) from a student perspective. Then, to improve accuracy, integrate subjective and objective textual knowledge from PRS-11 surveys and ChatGPT-4 on 200 SVI samples into VLM prompts via the Contrastive Language-Image Pretraining (CLIP) model. Further, using semantic networks to analyze VLM decision-making process within the perception-stimulus-restoration framework. Experimental results demonstrate that: 1) our method significantly outperformed Random Forest, with an RÂ² increase of 0.485 attributed to prior knowledge fusion; 2) restorative quality exhibits spatial heterogeneity, clustering near waterfronts, campus gates, and sports zones; and 3) semantic network analysis further revealed the decision rationales of VLMs across different restorative dimensions, providing design guidelines for low restorative quality spaces. This research offers a novel methodology for assessing campus restorative quality, providing practical tools for promoting sustainable campus development and advancing environmental psychology.
Keywords: Visual language model; Restorative quality; Campus spaces; Street view images; Attention Restoration Theory
